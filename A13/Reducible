#  File: Reducible.py

#  Description: A13; find longest reducible words

#  Student Name: Rin Chiang

#  Student UT EID: ksc2495

#  Partner Name:

#  Partner UT EID:

#  Course Name: CS 313E

#  Unique Number: 52530

#  Date Created: 10/18/2022

#  Date Last Modified:

import sys
import math

# Input: takes as input a positive integer n
# Output: returns True if n is prime and False otherwise
def is_prime (n):
    if (n == 1):
        return False

    for i in range(2, int(n / 2) + 1):
        if (n % i == 0):
            return False

    return True

# Input: takes as input a positive integer n (list length)
# Output: returns prime number that is greater than twice list length
def get_hash_size(n):
    test = n * 2 + 1
    if is_prime(test):
        return test
    else: 
        while (is_prime(test) == False):
            test += 1
            if is_prime(test):
                return test

# Input: takes as input a positive integer n, size of a hash_table
# Output: returns the largest prime number smaller than n, const
def get_const(n):
    test = n - 1
    for i in range(test, -1, -1):
        if is_prime(i):
            return i

# Input: takes as input a string in lower case and the size
#        of the hash table 
# Output: returns the index the string will hash into
def hash_word (s, size):
    hash_idx = 0
    for j in range (len(s)):
        letter = ord (s[j]) - 96
        hash_idx = (hash_idx * 26 + letter) % size
    return hash_idx

# Input: takes as input a string in lower case and the constant
#        for double hashing 
# Output: returns the step size for that string 
def step_size (s, const):
    step = 0
    for i in range(len(s)):
        letter = ord(s[i]) - 96
        step = (step * 26 + letter) % const
    return const - step

# Input: takes as input a string and a hash table 
# Output: no output; the function enters the string in the hash table, 
#         it resolves collisions by double hashing
def insert_word (s, hash_table):
    size = len(hash_table)
    pos = hash_word(s, size)
    new_pos

    # if pos is empty
    if (hash_table[pos] == ""):
        hash_table[pos] == s

    # if collision, find next spot
    else:
        const = get_const(size)
        step = step_size(s, const)

        searched = 1
        # until the entire hash table has been searched
        while searched < size:
            new_pos = (pos + searched * step) % size
            if (hash_table[new_pos] == ""):
                break
            searched += 1


# Input: takes as input a string and a hash table 
# Output: returns True if the string is in the hash table 
#         and False otherwise
def find_word (s, hash_table):
    size = len(hash_table)
    hash_bucket = hash_word(s, size)
    # catch cases where there were no collisions
    if (hash_table[hash_bucket] == s):
        return True
    # catch cases with possible collision
    else: 
        # call functions to get const and step
        const = get_const(size)
        step = step_size(s, const)
        # loop through the buckets, using double hashing
        buckets_probed = 1
        while (buckets_probed < size):
            # calculate the bucket in double hashing
            double_bucket = (hash_bucket + buckets_probed * step) % size
            if (hash_table[double_bucket] == s):
                return True
            else: 
                buckets_probed += 1
        return False

# Input: string s, a hash table, and a hash_memo 
#        recursively finds if the string is reducible
# Output: if the string is reducible it enters it into the hash memo 
#         and returns True and False otherwise
def is_reducible (s, hash_table, hash_memo):
    # # is s one of the 1 letter acceptable words
    # if (s == "a") or (s == "i") or (s == "o"):
    #     return True

    # # has s been found to be reducible
    # elif find_word(s, hash_memo):
    #     return True

    # check if s has already been determined as reducible
    if find_word(s, hash_memo):
        return True
    # if s is only one letter, see if it's accepted
    if len(s) == 1:
        return (s == 'a') or (s == 'i') or (s == 'o')
    # loop through characters in s
    for i in range(len(s)):
        # create test string with character at i removed
        test = s[:i] + s[i + 1:]
        # if test is an accepted word (is in the hash_table)
        if ((find_word(test, hash_table)) or (test == 'a') 
            or (test == 'i') or (test == 'o')):
            # check if test is a reducible word
            if is_reducible(test, hash_table, hash_memo):
                insert_word(s, hash_memo)
                return True
    '''
    print(s, 'NOT reducible')
    '''
    return False

# Input: string_list a list of words
# Output: returns a list of words that have the maximum length
def get_longest_words (string_list):
    # copy string_list and sort in reverse by length
    words = string_list
    sorted(words, key=lambda x: (-len(x), x))
    # find maximum length
    max_length = len(words[0])
    # create list to hold longest words
    long_words = []
    # loop through list words until length of the words[i] is not the max
    for i in range(len(words)):
        if (len(words[i]) == max_length):
            long_words.append(words[i])
        else: 
            break
    return long_words

def main():
    # create an empty word_list
    word_list = []
    # read words from words.txt and append to word_list
    for line in sys.stdin:
        line = line.strip()
        word_list.append(line)
    # find length of word_list
    length = len(word_list)
    '''
    print(f'Word list length is: {length}')
    '''
    # determine prime number N that is greater than twice
    # the length of the word_list
    N = get_hash_size(length)
    # create an empty hash_list
    hash_list = []
    # populate the hash_list with N blank strings
    hash_list = ['' for i in range(N)]
    '''
    print(f'Hash list size is: {len(hash_list)}')
    '''
    # hash each word in word_list into hash_list
    # for collisions use double hashing
    for word in word_list:
        insert_word(word, hash_list)
    # create an empty hash_memo of size M
    # we do not know a priori how many words will be reducible
    # let us assume it is 10 percent (fairly safe) of the words
    # then M is a prime number that is slightly greater than 
    # 0.2 * size of word_list
    M = get_hash_size(math.ceil(0.2 * length))
    hash_memo = []
    # populate the hash_memo with M blank strings
    hash_memo = ['' for i in range(M)]
    '''
    print(f'Hash memo size is: {len(hash_memo)}')
    '''
    # create an empty list reducible_words
    reducible_words = []
    # for each word in the word_list recursively determine
    # if it is reducible, if it is, add it to reducible_words
    # as you recursively remove one letter at a time check
    # first if the sub-word exists in the hash_memo. if it does
    # then the word is reducible and you do not have to test
    # any further. add the word to the hash_memo.
    word_list.sort(key = len)
    for word in word_list:
        if is_reducible(word, hash_list, hash_memo):
            reducible_words.append(word)
    # find the largest reducible words in reducible_words
    longest_words = get_longest_words(reducible_words)
    # print the reducible words in alphabetical order
    # one word per line
    longest_words.sort()
    for word in longest_words:
        print(word)

if __name__ == "__main__":
    main()